{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32 categories and 8840 files read.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "df=\"C:\\\\Users\\\\smartm13\\\\Desktop\\\\free codes\\\\herc-data\\\\herc-data\"\n",
    "catgs=[df+\"\\\\\"+f for f in os.listdir(df)]\n",
    "files=sum([[(f+\"\\\\\"+ff,f.split('\\\\')[-1]) for ff in os.listdir(f)] for f in catgs],[])\n",
    "print(len(catgs),\"categories and\",len(files),\"files read.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "locha=0\n"
     ]
    }
   ],
   "source": [
    "print(\"locha=\"+str(len((set([f[0].split('_')[-2].split(\"\\\\\")[-1] for f in files]))-set([c.split('\\\\')[-1] for c in catgs]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from PIL import Image,ImageOps\n",
    "def forCsvRow(fileadr,new_width=24,new_height=24):\n",
    "    img = Image.open(fileadr)\n",
    "    img = ImageOps.invert(img).resize((new_width, new_height), Image.ANTIALIAS)\n",
    "    return list(img.getdata())\n",
    "def genCSVs(files):\n",
    "    csv=[]\n",
    "    for fadr,fcatg in files:\n",
    "        csv.append([fcatg]+forCsvRow(fadr))\n",
    "    return csv\n",
    "def genCSVs(files):\n",
    "    for fadr,fcatg in files:\n",
    "        yield [fcatg]+forCsvRow(fadr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "with open(\"emnist_data_op.csv\",\"w+\") as my_csv:\n",
    "    csvWriter = csv.writer(my_csv,delimiter=',')\n",
    "    csvWriter.writerows(genCSVs(files[:]))\n",
    "print('check, file writing done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\smartm13\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2026: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd,numpy as np\n",
    "wdata=pd.read_csv(r\"emnist_data_op.csv\")\n",
    " \n",
    "catgs=wdata.iloc[:,0].tolist()\n",
    "catgSet=list(set(catgs))\n",
    "catgf=[catgSet.index(x) for x in catgs]\n",
    "wdata.iloc[:,0]=catgf\n",
    " \n",
    "from sklearn.model_selection import train_test_split\n",
    " \n",
    "train_db,test_db=train_test_split(wdata,random_state=42,train_size=.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_train: (5303, 32)\n",
      "x_train: (5303, 576)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\smartm13\\anaconda3\\envs\\tf\\lib\\site-packages\\ipykernel_launcher.py:19: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"de...)`\n",
      "c:\\users\\smartm13\\anaconda3\\envs\\tf\\lib\\site-packages\\ipykernel_launcher.py:27: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4772 samples, validate on 531 samples\n",
      "Epoch 1/10\n",
      " - 8s - loss: 3.2708 - acc: 0.2982 - val_loss: 2.9653 - val_acc: 0.4407\n",
      "Epoch 2/10\n",
      " - 0s - loss: 2.7010 - acc: 0.4834 - val_loss: 2.3778 - val_acc: 0.4934\n",
      "Epoch 3/10\n",
      " - 0s - loss: 2.1123 - acc: 0.5704 - val_loss: 1.8688 - val_acc: 0.6121\n",
      "Epoch 4/10\n",
      " - 0s - loss: 1.6481 - acc: 0.6565 - val_loss: 1.4899 - val_acc: 0.6742\n",
      "Epoch 5/10\n",
      " - 0s - loss: 1.3193 - acc: 0.7330 - val_loss: 1.2305 - val_acc: 0.7571\n",
      "Epoch 6/10\n",
      " - 0s - loss: 1.0967 - acc: 0.7816 - val_loss: 1.0520 - val_acc: 0.7797\n",
      "Epoch 7/10\n",
      " - 0s - loss: 0.9351 - acc: 0.8139 - val_loss: 0.9140 - val_acc: 0.8079\n",
      "Epoch 8/10\n",
      " - 0s - loss: 0.8143 - acc: 0.8363 - val_loss: 0.8143 - val_acc: 0.8267\n",
      "Epoch 9/10\n",
      " - 0s - loss: 0.7187 - acc: 0.8510 - val_loss: 0.7415 - val_acc: 0.8399\n",
      "Epoch 10/10\n",
      " - 0s - loss: 0.6444 - acc: 0.8659 - val_loss: 0.6851 - val_acc: 0.8418\n",
      "y_test: (3536, 32)\n",
      "x_test: (5303, 576)\n",
      "[0.7067755360948554, 0.8407805429864253]\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import np_utils\n",
    "from keras.layers import Input, Dense, Dropout\n",
    "from keras.models import Model\n",
    " \n",
    "num_classes = len(catgSet)\n",
    "y_train = train_db.iloc[:,0]\n",
    "y_train = np_utils.to_categorical(y_train, num_classes)\n",
    "print (\"y_train:\", y_train.shape)\n",
    " \n",
    "x_train = train_db.iloc[:,1:]\n",
    "x_train = x_train.astype('float32')\n",
    "x_train /= 255\n",
    "print (\"x_train:\",x_train.shape)\n",
    " \n",
    "inp = Input(shape=(len(wdata.columns)-1,))\n",
    "hidden_1 = Dense(1024, activation='relu')(inp)\n",
    "dropout_1 = Dropout(0.2)(hidden_1)\n",
    "out = Dense(num_classes, activation='softmax')(hidden_1)\n",
    "model = Model(input=inp, output=out)\n",
    " \n",
    "model.compile(loss='categorical_crossentropy', # using the cross-entropy loss function\n",
    "              optimizer='adam', # using the Adam optimiser\n",
    "              metrics=['accuracy']) # reporting the accuracy\n",
    " \n",
    "model.fit(x_train, y_train, # Train the model using the training set...\n",
    "          batch_size=512, nb_epoch=10,\n",
    "          verbose=2, validation_split=0.1) # ...holding out 10% of the data for validation\n",
    " \n",
    "y_test = test_db.iloc[:,0]\n",
    "y_test = np_utils.to_categorical(y_test, num_classes)\n",
    "print (\"y_test:\", y_test.shape)\n",
    " \n",
    "x_test = test_db.iloc[:,1:]\n",
    "x_test = x_test.astype('float32')\n",
    "x_test /= 255\n",
    "print (\"x_test:\",x_train.shape)\n",
    " \n",
    "print(model.evaluate(x_test, y_test, verbose=2)) # Evaluate the trained model on the test set!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
